# 一、HDFS架构 #

### 介绍 ###
1、具有高度的容错能力；  
2、旨在部署在低成本的硬件上；  
3、提供对应用程序数据的高吞吐量访问；  
4、适用于具有大数据集的应用程序；  
5、放宽了POSIX要求，以实现对文件系统数据的流式访问；  
6、最初是作为Apache Nutch Web搜索引擎项目的基础结构构建的。  

### 假设和目标 ###
1、硬件故障  
  假设：硬件故障是正常现象。  
  目标：检测故障并快速，自动地从故障中恢复。  
2、流数据访问  
  假设：运行在HDFS上的应用程序应该是可以对数据进行流式访问的。  
  目标：设计用于批处理，而不是用户交互使用；重点在于数据访问的高吞吐量，而不是数据访问的低延迟。  
3、大数据集  
假设：运行在HDFS上的应用程序应该是具有大量数据集的。  
目标：设计为支持存储大文件，提供较高的数据聚合带宽，可以扩展到成百上千个节点。  
4、简单一致性模型  
假设：HDFS应用程序需要文件一次写入多次读取的访问模型。  
目标：一旦创建、写入和关闭文件后，除了追加和截断外，无需更改；只能在文件末尾追加内容，不能在文件任意位置更改。  
5、“移动计算比移动数据更便宜”  
假设：通常是将计算迁移到更靠近数据的位置，而不是将数据迁移到应用程序运行的位置。  
目标：HDFS为应用程序提供了接口，使其运行在更靠近数据的位置。  
6、跨异构硬件和软件平台的可移植性  
假设：可以将HDFS移植到其他平台  
目标：将HDFS广泛用作大量应用程序的首选平台  

### NameNode和DataNodes ###
1、主/从结构。  
2、HDFS集群有一个NameNode和管理文件系统名称空间并控制客户端对文件访问的主服务器，以及许多数据节点。  
3、NameNode执行文件系统名称空间的操作，如打开，关闭和重命名文件和目录。还确定文件块到DataNode的映射。  
4、DataNode负责处理来自文件系统客户端的读写操作。还执行文件块的创建和删除等。  
![Image Text](https://github.com/fzqgithub/bigdata_doc/blob/master/hdfsarchitecture.png)

### 文件系统命名空间 ###
1、HDFS支持创建、删除、移动和重命名等文件操作。  
2、HDFS支持用户配额和访问权限。  
3、但暂不支持硬链接和软链接。  

### 资料复制 ###
1、复制品放置：第一步  
不同机架中的两个节点之间的通信必须通过交换机进行。  
在大多数情况下，同一机架间的计算机之间的网络带宽大于不同机架中的计算机之间的网络带宽。  
>当复制因子为3时，HDFS的放置策略是：如果写入程序位于数据节点上，则将一个副本放在本地计算机上，否则放在与写入程序位于同一机架中的随机数据节点上；另一个副本放在不同（远程）机架中的节点上；最后一个放在同一个远程机架中的不同节点上。此策略减少了机架间的写流量，提高了写性能，而不会影响数据的可靠性和读取性能。
>当复制因子大于3时，则在将每个机架的副本数保持在上限（(副本-1)/机架+2）的同时，随机确定第4个和后续副本的位置。  
由于NameNode不允许DataNode具有同一个块的多个副本，所以可创建的最大副本数是DataNode的总数。  

2、副本选择  
为了最大程度地减少全局带宽消耗和读取延迟，HDFS尝试满足最接近读取器的副本的读取请求。

3、安全模式  
HDFS启动时，NameNode会先进入一个特殊的状态，称为安全模式。处于该模式时，不会复制数据块。  
NameNode从DataNodes接收Heartbeat和Blockreport信息。Blockreport包含数据节点托管的数据块列表。每个块都有指定的最小副本数。  
当数据块的最小副本数签入NameNode时，块被认为是安全复制的。在安全复制数据块的可配置百分比与NameNode一起检查（加上另外30秒）之后，NameNode退出安全模式。  然后，它确定仍具有少于指定副本数的数据块的列表。  
最后，NameNode将这些块复制到其他数据节点。  

### 文件系统元数据的持久性 ###
HDFS命名空间由NameNode存储。  
NameNode使用使用一个称为EditLog的事务日志来永久记录文件系统元数据发生的每个更改。
整个文件系统命名空间（包含块到文件的映射和文件系统属性）存储在名为FsImage的文件中。  
NameNode将整个文件系统名称空间和文件块映射的图像保存在内存中。当NameNode启动时，或者检查点由可配置的阈值触发时，它从磁盘读取FsImage和EditLog，将EditLog中的所有事务应用于FsImage的内存表示，并将此新版本刷新到磁盘上的新FsImage中。然后，它可以截断旧的EditLog，因为它的事务已应用于持久的FsImage。这个过程称为检查点。检查点的目的是通过获取文件系统元数据的快照并将其保存到FsImage，确保HDFS具有文件系统元数据的一致视图。尽管读取FsImage是有效的，但是直接对FsImage进行增量编辑是无效的。我们没有为每次编辑修改FsImage，而是将编辑保存在Editlog中。在检查点期间，来自Editlog的更改将应用于FsImage。检查点可以在给定的时间间隔（dfs.namenode.checkpoint.period，以秒为单位）触发，或者在给定数量的文件系统事务累积之后（dfs.namenode.checkpoint.txns）触发。如果设置了这两个属性，则要达到的第一个阈值将触发检查点。  
DataNode将HDFS数据存储在其本地文件系统中的文件中。DataNode不知道HDFS文件。它将每个HDFS数据块存储在本地文件系统中的单独文件中。DataNode不会在同一目录中创建所有文件。相反，它使用启发式方法来确定每个目录的最佳文件数，并相应地创建子目录。在同一目录中创建所有本地文件不是最佳选择，因为本地文件系统可能无法有效地支持单个目录中的大量文件。当DataNode启动时，它会扫描其本地文件系统，生成与每个本地文件对应的所有HDFS数据块的列表，并将此报告发送到NameNode。该报告称为Blockreport。  

### 通讯协议 ### 
所有HDFS通信协议都位于TCP / IP协议之上。  
客户端建立与NameNode计算机上可配置TCP端口的连接。它将ClientProtocol与NameNode进行通信。  
DataNode使用DataNode协议与NameNode对话。  
远程过程调用（RPC）抽象包装了客户端协议和DataNode协议。  
按照设计，NameNode永远不会启动任何RPC。相反，它仅响应由DataNode或客户端发出的RPC请求。  

### 坚固性 ### 
HDFS的主要目标是即使出现故障也能可靠地存储数据。三种常见的故障类型是NameNode故障，DataNode故障和网络分区。  
1、数据磁盘故障，心跳和复制  
每个DataNode定期向NameNode发送心跳消息。网络分区可能导致一部分DataNode失去与NameNode的连接。  
NameNode通过缺少心跳消息来检测到这种情况。NameNode将没有最近心跳的DataNode标记为已死，并且不会将任何新的IO请求转发给它们。已注册到失效DataNode的任何数据不再可用于HDFS。  
DataNode死亡可能导致某些块的复制因子降至其指定值以下。NameNode不断跟踪需要复制的块，并在必要时启动复制。由于许多原因，可能需要进行重新复制：DataNode可能不可用，副本可能损坏，DataNode上的硬盘可能发生故障。  
将数据节点标记为死亡的超时时间是保守的长（默认情况下超过10分钟），以避免由于数据节点的状态波动而导致的复制风暴。对于性能敏感的工作负载，用户可以设置较短的间隔以将数据节点标记为过时，并通过配置在读取和/或写入时避免过时节点。  

2、集群再平衡  
HDFS体系结构与数据重新平衡方案兼容。如果DataNode的可用空间低于某个阈值，则方案可能会自动将数据从一个DataNode移至另一个DataNode。如果对特定文件的需求突然增加，则方案可能会动态创建其他副本并重新平衡群集中的其他数据。  

3、数据的完整性  
从DataNode提取的数据块可能会损坏。由于存储设备故障，网络故障或软件故障，可能会导致这种损坏。  
HDFS客户端软件对HDFS文件的内容执行校验和检查。  
客户端创建HDFS文件时，它将计算文件每个块的校验和，并将这些校验和存储在同一HDFS命名空间中的单独的隐藏文件中。客户端检索文件内容时，它将验证从每个DataNode接收的数据是否与存储在关联的校验和文件中的校验和匹配。如果不是，则客户端可以选择从另一个具有该块副本的DataNode中检索该块。  

4、元数据磁盘故障  
FsImage和EditLog是HDFS的中央数据结构。这些文件损坏可能导致HDFS实例无法正常运行。因此，可以将NameNode配置为支持维护FsImage和EditLog的多个副本。  
FsImage和EditLog的多个副本的这种同步更新可能会降低NameNode可以支持的每秒名称空间事务处理的速度。但是，这种降级是可以接受的，因为即使HDFS应用程序本质上是数据密集型的，但它们也不是元数据密集型的。  
当NameNode重新启动时，它将选择要使用的最新一致的FsImage和EditLog。  
增强抗故障能力的另一种方法是使用多个NameNode来启用高可用性，这些NameNode可以在NFS上使用共享存储，也可以使用分布式编辑日志（称为Journal）。推荐使用后者。  

5、快照  
快照支持在特定时间存储数据副本。  
快照功能的一种用法可能是将损坏的HDFS实例回滚到以前已知的良好时间点。  

### 资料组织 ###
1、数据块  
HDFS旨在支持非常大的文件。  
与HDFS兼容的应用程序是处理大型数据集的应用程序。这些应用程序仅写入一次数据，但读取一次或多次，并要求以流速度满足这些读取要求。  
HDFS使用的典型块大小为128 MB。  

2、复制管道  
当客户端将数据写入复制因子为3的HDFS文件时，NameNode使用复制目标选择算法检索数据节点列表。此列表包含将承载该块副本的数据节点。  
然后客户端写入第一个数据节点。第一个数据节点开始接收部分数据，将每个部分写入其本地存储库，并将该部分传输到列表中的第二个数据节点。  
第二个数据节点依次开始接收数据块的每个部分，将该部分写入其存储库，然后将该部分刷新到第三个数据节点。  
最后，第三个数据节点将数据写入其本地存储库。  
因此，数据节点可以从管道中的前一个节点接收数据，同时将数据转发到管道中的下一个节点。因此，数据是从一个数据节点到下一个数据节点的流水线。  

### 辅助功能 ###
可以通过许多不同的方式从应用程序访问HDFS。  
1、FS Shell  
FS Shell适用于需要脚本语言与存储的数据进行交互的应用程序。  

2、FileSystem Java API  

3、DFSAdmin  
DFSAdmin命令集用于管理HDFS群集。这些是仅由HDFS管理员使用的命令。  

4、浏览器界面  
典型的HDFS安装会将Web服务器配置为通过可配置的TCP端口公开HDFS命名空间。这允许用户使用Web浏览器浏览HDFS命名空间并查看其文件的内容。  

### 空间回收 ###
1、文件删除和取消删除  
如果启用垃圾箱配置，则不会立即从HDFS中删除由FS Shell删除的文件。而是，HDFS将其移动到回收站目录（每个用户在/ user / <用户名> /。Trash下都有自己的回收站目录）。只要文件保留在垃圾桶中，就可以快速恢复。  
在垃圾桶中使用寿命到期后，NameNode将从HDFS命名空间中删除该文件。删除文件会释放与文件关联的块。  
注意，在用户删除文件的时间和HDFS中相应的空闲空间增加的时间之间可能存在可观的时间延迟。  

2、减少复制因子  
当文件的复制因子降低时，NameNode将选择可删除的多余副本。下一个Heartbeat将此信息传输到DataNode。然后，DataNode删除相应的块，相应的可用空间出现在集群中。  
同样，在setReplication API调用完成与群集中的可用空间出现之间可能会有时间延迟。  

** HDFS源代码：http : //hadoop.apache.org/version_control.html **
** Hadoop源代码位于Apache git存储库中，可从以下位置获取：https://github.com/apache/hadoop **
** 所做的更改也反映到github存储库：https://gitbox.apache.org/repos/asf?p=hadoop.git **














































































